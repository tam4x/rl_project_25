{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tam4x/rl_project_25.git\n",
        "!pip install -r rl_project_25/requirements.txt\n",
        "import sys\n",
        "sys.path.append(\"/content/rl_project_25\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCnwWXsIkkrd",
        "outputId": "0601da5d-3420-4e9c-e2a0-cf1ed7b4e1b8"
      },
      "id": "sCnwWXsIkkrd",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rl_project_25'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 84 (delta 17), reused 68 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (84/84), 25.29 MiB | 16.35 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r rl_project_25/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r rl_project_25/requirements.txt (line 4)) (2.9.0+cu126)\n",
            "Requirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.12/dist-packages (from -r rl_project_25/requirements.txt (line 2)) (1.2.2)\n",
            "Collecting stable-baselines3[extra] (from -r rl_project_25/requirements.txt (line 3))\n",
            "  Downloading stable_baselines3-2.7.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (0.0.4)\n",
            "Collecting mujoco>=2.1.5 (from gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2))\n",
            "  Downloading mujoco-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (2.37.2)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (25.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r rl_project_25/requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (1.13.0)\n",
            "Collecting glfw (from mujoco>=2.1.5->gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2))\n",
            "  Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco>=2.1.5->gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (3.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r rl_project_25/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (5.29.5)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r rl_project_25/requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (2025.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]->-r rl_project_25/requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco>=2.1.5->gymnasium[mujoco]->-r rl_project_25/requirements.txt (line 2)) (3.23.0)\n",
            "Downloading mujoco-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.7.1-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.p39.p310.p311.p312.p313-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco, stable-baselines3\n",
            "Successfully installed glfw-2.10.0 mujoco-3.4.0 stable-baselines3-2.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"/content/teachers/HC_RUN_v6.0_SAC.zip\")\n"
      ],
      "metadata": {
        "id": "py64xINO83g1",
        "outputId": "db58e9c4-90b9-4493-bdd1-39323f7e8233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "id": "py64xINO83g1",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9e390510-6eab-4a1c-ba79-9650fbde00b9\", \"HC_RUN_v6.0_SAC.zip\", 3241838)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207c7fad",
      "metadata": {
        "id": "207c7fad"
      },
      "source": [
        "##### Import Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1c7af34a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c7af34a",
        "outputId": "c0f711b9-3008-4467-cf43-0d6bcc4ee66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable, Dict, Any, Tuple, List\n",
        "import os\n",
        "import numpy as np\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from src.teacher import Task\n",
        "from src.teacher import train_teacher_for_task, task_base, task_halfcheetah_target_velocity\n",
        "from src.teacher import task_walker2d_target_velocity\n",
        "from src.memory import load_sac_teacher, collect_memory_from_sac_teacher, save_memory_npz\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "51aa01f2",
      "metadata": {
        "id": "51aa01f2"
      },
      "outputs": [],
      "source": [
        "tasks = [\n",
        "    Task(\"BASE HalfCheetah\", lambda: task_base(\"HalfCheetah-v4\", seed=0)),\n",
        "    Task(\"BASE Walker2d\",    lambda: task_base(\"Walker2d-v4\", seed=0)),\n",
        "]\n",
        "\n",
        "halfcheetah_tasks = [\n",
        "    #Task(\"HC_WALK_v1.0\",  lambda: task_halfcheetah_target_velocity( 1.0, seed=0)),\n",
        "    #Task(\"HC_RUN_v6.0\",   lambda: task_halfcheetah_target_velocity( 6.0, seed=0)),\n",
        "    Task(\"HC_BACK_v-1.0\", lambda: task_halfcheetah_target_velocity(-1.0, seed=0)),\n",
        "]\n",
        "\n",
        "walker_tasks = [\n",
        "    Task(\"W_WALK_v1.0\",  lambda: task_walker2d_target_velocity( 1.0, seed=1)),\n",
        "    Task(\"W_RUN_v3.5\",   lambda: task_walker2d_target_velocity( 3.5, seed=1)),\n",
        "    Task(\"W_BACK_v-1.0\", lambda: task_walker2d_target_velocity(-1.0, seed=1)),\n",
        "    # Optional (add later):\n",
        "    # Task(\"W_JUMP\", lambda: task_walker2d_jump(seed=1, baseline_height=1.25, beta=5.0)),\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "29848036",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "29848036",
        "outputId": "1a3b8863-142c-49b4-d756-7cb397b9078c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Using cuda device\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Using cuda device\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Logging to ./tb_logs/SAC_4\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Logging to ./tb_logs/SAC_4\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "LiveError",
          "evalue": "Only one live display may be active at once",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLiveError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4197971075.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhalfcheetah_tasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     res = train_teacher_for_task(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAC\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/rl_project_25/src/teacher.py\u001b[0m in \u001b[0;36mtrain_teacher_for_task\u001b[0;34m(task, algo, total_timesteps, seed, normalize_obs, out_dir, log_dir)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_teacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvenv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mvenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/sac/sac.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     ) -> SelfSAC:\n\u001b[0;32m--> 313\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/off_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You must set the environment before calling learn()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Update num_timesteps in case training was done before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_training_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_training_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_training_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_training_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_rollout_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36mon_training_start\u001b[0;34m(self, locals_, globals_)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Update num_timesteps in case training was done before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_training_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_training_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/callbacks.py\u001b[0m in \u001b[0;36m_on_training_start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;31m# Initialize progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;31m# Remove timesteps that were done in previous training sessions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"total_timesteps\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/rich.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'transient'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rich/progress.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rich/progress.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;34m\"\"\"Start the progress display.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rich/live.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, refresh)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_live\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_screen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/rich/console.py\u001b[0m in \u001b[0;36mset_live\u001b[0;34m(self, live)\u001b[0m\n\u001b[1;32m    833\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_live\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLiveError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only one live display may be active at once\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_live\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLiveError\u001b[0m: Only one live display may be active at once"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for t in halfcheetah_tasks:\n",
        "    res = train_teacher_for_task(\n",
        "        task=t,\n",
        "        algo=\"SAC\",\n",
        "        total_timesteps=1_000_000,  # recommended for shaped tasks; 300k may be low\n",
        "        seed=0,\n",
        "        normalize_obs=True,\n",
        "        out_dir=\"./teachers\",\n",
        "        log_dir=\"./tb_logs\",\n",
        "    )\n",
        "    results.append(res)\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5aa43abe",
      "metadata": {
        "id": "5aa43abe"
      },
      "outputs": [],
      "source": [
        "results = [{'task': 'BASE HalfCheetah', 'algo': 'SAC', 'mean': np.float64(8743.4280451), 'std': np.float64(122.44090484187974), 'model_path': './teachers/BASE HalfCheetah_SAC.zip', 'vec_path': './teachers/BASE HalfCheetah_SAC_vecnormalize.pkl'},\n",
        "{'task': 'BASE Hopper', 'algo': 'SAC', 'mean': np.float64(3534.9982952), 'std': np.float64(74.30036539246545), 'model_path': './teachers/BASE Hopper_SAC.zip', 'vec_path': './teachers/BASE Hopper_SAC_vecnormalize.pkl'},\n",
        "{'task': 'BASE Walker2d', 'algo': 'SAC', 'mean': np.float64(4432.8367175), 'std': np.float64(88.3051954926245), 'model_path': './teachers/BASE Walker2d_SAC.zip', 'vec_path': './teachers/BASE Walker2d_SAC_vecnormalize.pkl'},\n",
        "{'task': 'BASE Ant', 'algo': 'SAC', 'mean': np.float64(3602.8521288), 'std': np.float64(70.70085649305115), 'model_path': './teachers/BASE Ant_SAC.zip', 'vec_path': './teachers/BASE Ant_SAC_vecnormalize.pkl'}]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3jOGJeXGp5EQ",
      "metadata": {
        "id": "3jOGJeXGp5EQ"
      },
      "source": [
        "##### Load Teacher for Memory Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lWyFoytksMXB",
      "metadata": {
        "id": "lWyFoytksMXB"
      },
      "outputs": [],
      "source": [
        "MEM_DIR = \"./memory_sac\"\n",
        "all_mem_paths = []\n",
        "\n",
        "for i, t in enumerate(tasks):\n",
        "\n",
        "    r = results[i]\n",
        "\n",
        "    model, venv = load_sac_teacher(t, r[\"model_path\"], r[\"vec_path\"], seed=0)\n",
        "\n",
        "    mem = collect_memory_from_sac_teacher(\n",
        "        model=model,\n",
        "        venv=venv,\n",
        "        task_name=t.name,\n",
        "        n_steps=50_000,                # start small to validate\n",
        "        deterministic_action=True,     # or False to cover more state space\n",
        "        store_actions=True,\n",
        "        seed=123\n",
        "    )\n",
        "\n",
        "    out_path = os.path.join(MEM_DIR, f\"{t.name}_SAC_memory.npz\")\n",
        "    save_memory_npz(mem, out_path)\n",
        "    all_mem_paths.append(out_path)\n",
        "\n",
        "    venv.close()\n",
        "\n",
        "all_mem_paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N6QXvmXJvvGJ",
      "metadata": {
        "id": "N6QXvmXJvvGJ"
      },
      "outputs": [],
      "source": [
        "class DistillMemoryDataset(Dataset):\n",
        "    def __init__(self, npz_path: str):\n",
        "        d = np.load(npz_path, allow_pickle=True)\n",
        "        self.obs = d[\"obs\"].astype(np.float32)\n",
        "        self.mu_t = d[\"mu\"].astype(np.float32)\n",
        "        self.log_std_t = d[\"log_std\"].astype(np.float32)\n",
        "        self.action_t = d[\"action\"].astype(np.float32) if \"action\" in d.files else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.obs.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        obs = self.obs[idx]\n",
        "        mu_t = self.mu_t[idx]\n",
        "        log_std_t = self.log_std_t[idx]\n",
        "        if self.action_t is None:\n",
        "            return obs, mu_t, log_std_t\n",
        "        return obs, mu_t, log_std_t, self.action_t[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8D32MzIqw4vO",
      "metadata": {
        "id": "8D32MzIqw4vO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GaussianStudentPolicy(nn.Module):\n",
        "    def __init__(self, obs_dim, act_dim, hidden=(256, 256), log_std_bounds=(-5.0, 2.0)):\n",
        "        super().__init__()\n",
        "        self.log_std_min, self.log_std_max = log_std_bounds\n",
        "\n",
        "        layers = []\n",
        "        in_dim = obs_dim\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(in_dim, h), nn.ReLU()]\n",
        "            in_dim = h\n",
        "        self.backbone = nn.Sequential(*layers)\n",
        "\n",
        "        self.mu_head = nn.Linear(in_dim, act_dim)\n",
        "        self.log_std_head = nn.Linear(in_dim, act_dim)\n",
        "\n",
        "    def forward(self, obs, return_features=False):\n",
        "        z = self.backbone(obs)  # student latent\n",
        "        mu = self.mu_head(z)\n",
        "        log_std = torch.clamp(self.log_std_head(z), self.log_std_min, self.log_std_max)\n",
        "        if return_features:\n",
        "            return mu, log_std, z\n",
        "        return mu, log_std\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ezIQ-GJyxc-",
      "metadata": {
        "id": "4ezIQ-GJyxc-"
      },
      "source": [
        "##### Distillation Method 1 and 2 use soft and hard label actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QvrLdOGPw-yn",
      "metadata": {
        "id": "QvrLdOGPw-yn"
      },
      "outputs": [],
      "source": [
        "# D1\n",
        "def diag_gaussian_kl(mu_t, log_std_t, mu_s, log_std_s):\n",
        "    # shapes: (B, act_dim)\n",
        "    std_t = torch.exp(log_std_t)\n",
        "    std_s = torch.exp(log_std_s)\n",
        "\n",
        "    var_t = std_t ** 2\n",
        "    var_s = std_s ** 2\n",
        "\n",
        "    kl = (log_std_s - log_std_t) + (var_t + (mu_t - mu_s) ** 2) / (2.0 * var_s) - 0.5\n",
        "    return kl.sum(dim=-1).mean()  # mean over batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CKAURSftxDGE",
      "metadata": {
        "id": "CKAURSftxDGE"
      },
      "outputs": [],
      "source": [
        "# D2\n",
        "def action_mse(mu_s, action_t):\n",
        "    return F.mse_loss(mu_s, action_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6gEQHUeYylpK",
      "metadata": {
        "id": "6gEQHUeYylpK"
      },
      "source": [
        "##### Distillation Method 3 uses weighted certainty. States where the teacher is sure what to do are weighted harder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eS_1zyApxI8E",
      "metadata": {
        "id": "eS_1zyApxI8E"
      },
      "outputs": [],
      "source": [
        "# D3\n",
        "def certainty_weights(log_std_t, eps=1e-6):\n",
        "    # weight per sample (B,)\n",
        "    std_t = torch.exp(log_std_t)              # (B, act_dim)\n",
        "    w = 1.0 / (eps + std_t.mean(dim=-1))      # (B,)\n",
        "    # normalize weights to keep scale stable\n",
        "    w = w / (w.mean() + 1e-8)\n",
        "    return w\n",
        "\n",
        "def weighted_diag_gaussian_kl(mu_t, log_std_t, mu_s, log_std_s):\n",
        "    std_t = torch.exp(log_std_t)\n",
        "    std_s = torch.exp(log_std_s)\n",
        "    var_t = std_t ** 2\n",
        "    var_s = std_s ** 2\n",
        "\n",
        "    kl_per_dim = (log_std_s - log_std_t) + (var_t + (mu_t - mu_s) ** 2) / (2.0 * var_s) - 0.5\n",
        "    kl_per_sample = kl_per_dim.sum(dim=-1)  # (B,)\n",
        "\n",
        "    w = certainty_weights(log_std_t)         # (B,)\n",
        "    return (w * kl_per_sample).mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "096d476a",
      "metadata": {
        "id": "096d476a"
      },
      "source": [
        "##### Distillation Method 4 uses the internal representations of the teacher for the student"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ec8b2c",
      "metadata": {
        "id": "73ec8b2c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "@torch.no_grad()\n",
        "def sac_teacher_latent(model, obs_batch_np):\n",
        "    \"\"\"\n",
        "    Returns teacher actor latent features for given (normalized) obs batch.\n",
        "    obs_batch_np: (B, obs_dim) or (1, obs_dim)\n",
        "    \"\"\"\n",
        "    actor = model.policy.actor\n",
        "    obs = torch.as_tensor(obs_batch_np, dtype=torch.float32, device=model.device)\n",
        "\n",
        "    # Most SB3 versions have features_extractor + latent_pi\n",
        "    if hasattr(actor, \"features_extractor\") and hasattr(actor, \"latent_pi\"):\n",
        "        feat = actor.features_extractor(obs)\n",
        "        lat = actor.latent_pi(feat)\n",
        "        return lat\n",
        "\n",
        "    # Fallback: some versions use extract_features()\n",
        "    if hasattr(actor, \"extract_features\") and hasattr(actor, \"latent_pi\"):\n",
        "        feat = actor.extract_features(obs)\n",
        "        lat = actor.latent_pi(feat)\n",
        "        return lat\n",
        "\n",
        "    raise AttributeError(\"Could not locate actor latent pathway. Inspect model.policy.actor to adapt extractor.\")\n",
        "\n",
        "class Projector(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_dim, out_dim)\n",
        "    def forward(self, x):\n",
        "        return self.proj(x)\n",
        "\n",
        "\n",
        "def latent_cosine_loss(z_t, z_s_proj):\n",
        "    # (B, D): 1 - cosine similarity\n",
        "    return 1.0 - F.cosine_similarity(z_s_proj, z_t, dim=-1).mean()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cbc43b0",
      "metadata": {
        "id": "1cbc43b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def snapshot_params(model: torch.nn.Module):\n",
        "    \"\"\"Detached copy of all trainable parameters (for anchoring).\"\"\"\n",
        "    return [p.detach().clone() for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "def anchor_loss(model: torch.nn.Module, anchor_params, coeff: float):\n",
        "    \"\"\"L2 penalty to keep parameters close to anchor snapshot.\"\"\"\n",
        "    if coeff <= 0 or anchor_params is None:\n",
        "        return 0.0\n",
        "\n",
        "    loss = 0.0\n",
        "    i = 0\n",
        "    for p in model.parameters():\n",
        "        if p.requires_grad:\n",
        "            loss = loss + torch.sum((p - anchor_params[i]) ** 2)\n",
        "            i += 1\n",
        "    return coeff * loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hls4okslxrkM",
      "metadata": {
        "id": "hls4okslxrkM"
      },
      "outputs": [],
      "source": [
        "def train_distill_step_no_replay(\n",
        "    student,                       # <-- external student (keeps weights)\n",
        "    method: str,\n",
        "    current_npz: str,\n",
        "    teacher_sac_model=None,        # only needed for D4_KL_LATENT\n",
        "    projector=None,                # optional, for D4\n",
        "    epochs: int = 10,\n",
        "    batch_size: int = 256,\n",
        "    lr: float = 3e-4,\n",
        "    lambda_feat: float = 0.05,     # D4 only\n",
        "    anchor_coeff: float = 1e-6,    # keep small; tunes stability vs plasticity\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Sequential offline distillation on *current task only* (no replay),\n",
        "    with optional weight anchoring to reduce overwriting.\n",
        "\n",
        "    Returns:\n",
        "      student (same object, updated), projector (for D4 if used)\n",
        "    \"\"\"\n",
        "    method = method.upper()\n",
        "\n",
        "    # --- data (current task only) ---\n",
        "    ds = DistillMemoryDataset(current_npz)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "    student = student.to(device)\n",
        "\n",
        "    # Anchor snapshot BEFORE learning this task\n",
        "    anchor_params = snapshot_params(student) if anchor_coeff > 0 else None\n",
        "\n",
        "    # --- projector setup for D4 ---\n",
        "    if method == \"D4_KL_LATENT\":\n",
        "        if teacher_sac_model is None:\n",
        "            raise ValueError(\"D4_KL_LATENT requires teacher_sac_model.\")\n",
        "\n",
        "        if projector is None:\n",
        "            # infer dims from small sample\n",
        "            sample_obs = ds.obs[:8].astype(np.float32)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # student latent dim\n",
        "                obs_t = torch.as_tensor(sample_obs, dtype=torch.float32, device=device)\n",
        "                _, _, z_s = student(obs_t, return_features=True)\n",
        "                student_lat_dim = int(z_s.shape[-1])\n",
        "\n",
        "                # teacher latent dim\n",
        "                z_t = sac_teacher_latent(teacher_sac_model, sample_obs).detach().cpu()\n",
        "                teacher_lat_dim = int(z_t.shape[-1])\n",
        "\n",
        "            projector = Projector(student_lat_dim, teacher_lat_dim).to(device)\n",
        "        else:\n",
        "            projector = projector.to(device)\n",
        "\n",
        "        opt = torch.optim.Adam(list(student.parameters()) + list(projector.parameters()), lr=lr)\n",
        "    else:\n",
        "        opt = torch.optim.Adam(student.parameters(), lr=lr)\n",
        "\n",
        "    # --- training loop ---\n",
        "    for ep in range(1, epochs + 1):\n",
        "        losses = []\n",
        "        for batch in dl:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            if len(batch) == 3:\n",
        "                obs, mu_t, log_std_t = batch\n",
        "                action_t = None\n",
        "            else:\n",
        "                obs, mu_t, log_std_t, action_t = batch\n",
        "\n",
        "            obs = obs.to(device)\n",
        "            mu_t = mu_t.to(device)\n",
        "            log_std_t = log_std_t.to(device)\n",
        "            if action_t is not None:\n",
        "                action_t = action_t.to(device)\n",
        "\n",
        "            # Forward student\n",
        "            if method == \"D4_KL_LATENT\":\n",
        "                mu_s, log_std_s, z_s = student(obs, return_features=True)\n",
        "            else:\n",
        "                mu_s, log_std_s = student(obs)\n",
        "\n",
        "            # Base loss by method\n",
        "            if method == \"D1_KL\":\n",
        "                loss = diag_gaussian_kl(mu_t, log_std_t, mu_s, log_std_s)\n",
        "\n",
        "            elif method == \"D2_MSE\":\n",
        "                if action_t is None:\n",
        "                    raise ValueError(\"D2_MSE needs 'action' stored in npz.\")\n",
        "                loss = action_mse(mu_s, action_t)\n",
        "\n",
        "            elif method == \"D3_WKL\":\n",
        "                loss = weighted_diag_gaussian_kl(mu_t, log_std_t, mu_s, log_std_s)\n",
        "\n",
        "            elif method == \"D4_KL_LATENT\":\n",
        "                loss_policy = diag_gaussian_kl(mu_t, log_std_t, mu_s, log_std_s)\n",
        "\n",
        "                # teacher latent on-the-fly (obs are normalized already)\n",
        "                z_t = sac_teacher_latent(teacher_sac_model, obs.detach().cpu().numpy()).to(device)\n",
        "\n",
        "                z_s_proj = projector(z_s)\n",
        "                loss_lat = latent_cosine_loss(z_t, z_s_proj)\n",
        "\n",
        "                loss = loss_policy + lambda_feat * loss_lat\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Unknown method. Use: D1_KL, D2_MSE, D3_WKL, D4_KL_LATENT\")\n",
        "\n",
        "            # Add anchor penalty (prevents large drift on new task)\n",
        "            if anchor_coeff > 0:\n",
        "                loss = loss + anchor_loss(student, anchor_params, anchor_coeff)\n",
        "\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            losses.append(float(loss.item()))\n",
        "\n",
        "        # print occasionally\n",
        "        if ep == 1 or ep % 10 == 0:\n",
        "            extra = f\" (lambda_feat={lambda_feat})\" if method == \"D4_KL_LATENT\" else \"\"\n",
        "            print(f\"Epoch {ep:02d} | {method} loss: {np.mean(losses):.4f} | anchor={anchor_coeff}{extra}\")\n",
        "\n",
        "    return student, projector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QYU_pp7Yx31q",
      "metadata": {
        "id": "QYU_pp7Yx31q"
      },
      "outputs": [],
      "source": [
        "def save_student(student, path: str):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save(student.state_dict(), path)\n",
        "    print(\"Saved student:\", path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sF5aBtHJ1Imf",
      "metadata": {
        "id": "sF5aBtHJ1Imf"
      },
      "source": [
        "##### Eval in a Normalized Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ehPhkCjO1H5v",
      "metadata": {
        "id": "ehPhkCjO1H5v"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def make_base_vec_env(env_id: str, seed: int = 0):\n",
        "    def _init():\n",
        "        env = gym.make(env_id)\n",
        "        env = Monitor(env)\n",
        "        env.reset(seed=seed)\n",
        "        return env\n",
        "    return DummyVecEnv([_init])\n",
        "\n",
        "def load_eval_env_with_vecnorm(env_id: str, vec_path: str, seed: int = 0):\n",
        "    venv = make_base_vec_env(env_id, seed=seed)\n",
        "    venv = VecNormalize.load(vec_path, venv)\n",
        "    venv.training = False\n",
        "    venv.norm_reward = False\n",
        "    return venv\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_offline_student(student, venv, n_episodes=10, device=None):\n",
        "    if device is None:\n",
        "        device = next(student.parameters()).device\n",
        "    student.eval()\n",
        "\n",
        "    rets = []\n",
        "    for _ in range(n_episodes):\n",
        "        obs = venv.reset()        # normalized obs (shape (1, obs_dim))\n",
        "        done = [False]\n",
        "        ep_ret = 0.0\n",
        "\n",
        "        while not done[0]:\n",
        "            obs_t = torch.as_tensor(obs, dtype=torch.float32, device=device)\n",
        "            mu, log_std = student(obs_t)\n",
        "\n",
        "            # MuJoCo expects actions in [-1, 1]; match SAC-style squashing:\n",
        "            action = torch.tanh(mu).cpu().numpy()\n",
        "\n",
        "            obs, reward, done, info = venv.step(action)\n",
        "            ep_ret += float(reward[0])\n",
        "\n",
        "        rets.append(ep_ret)\n",
        "\n",
        "    return float(np.mean(rets)), float(np.std(rets))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vj7Udo_m3cFS",
      "metadata": {
        "id": "vj7Udo_m3cFS"
      },
      "source": [
        "##### Training Run for Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DIef_MFU3eSD",
      "metadata": {
        "id": "DIef_MFU3eSD"
      },
      "outputs": [],
      "source": [
        "TASK_SEQUENCE = [\n",
        "    {\n",
        "        \"name\": \"BASE HalfCheetah\",\n",
        "        \"env_id\": \"HalfCheetah-v4\",\n",
        "        \"npz_path\": \"./memory_sac/BASE HalfCheetah_SAC_memory.npz\",\n",
        "        \"model_path\": \"./teachers/BASE HalfCheetah_SAC.zip\",\n",
        "        \"vec_path\": \"./teachers/BASE HalfCheetah_SAC_vecnormalize.pkl\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"BASE Hopper\",\n",
        "        \"env_id\": \"Hopper-v4\",\n",
        "        \"npz_path\": \"./memory_sac/BASE Hopper_SAC_memory.npz\",\n",
        "        \"model_path\": \"./teachers/BASE Hopper_SAC.zip\",\n",
        "        \"vec_path\": \"./teachers/BASE Hopper_SAC_vecnormalize.pkl\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"BASE Walker2d\",\n",
        "        \"env_id\": \"Walker2d-v4\",\n",
        "        \"npz_path\": \"./memory_sac/BASE Walker2d_SAC_memory.npz\",\n",
        "        \"model_path\": \"./teachers/BASE Walker2d_SAC.zip\",\n",
        "        \"vec_path\": \"./teachers/BASE Walker2d_SAC_vecnormalize.pkl\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"BASE Ant\",\n",
        "        \"env_id\": \"Ant-v4\",\n",
        "        \"npz_path\": \"./memory_sac/BASE Ant_SAC_memory.npz\",\n",
        "        \"model_path\": \"./teachers/BASE Ant_SAC.zip\",\n",
        "        \"vec_path\": \"./teachers/BASE Ant_SAC_vecnormalize.pkl\",\n",
        "    },\n",
        "]\n",
        "\n",
        "# infer obs_dim / act_dim from first task memory\n",
        "tmp = np.load(TASK_SEQUENCE[0][\"npz_path\"], allow_pickle=True)\n",
        "obs_dim = tmp[\"obs\"].shape[1]\n",
        "act_dim = tmp[\"mu\"].shape[1]\n",
        "\n",
        "student = GaussianStudentPolicy(obs_dim, act_dim)\n",
        "projector = None  # used only for D4\n",
        "methods = [\"D1_KL\", \"D2_MSE\", \"D3_WKL\", \"D4_KL_LATENT\"]\n",
        "method = methods[0]\n",
        "\n",
        "for i, cfg in enumerate(TASK_SEQUENCE):\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\" Training task {i+1}/{len(TASK_SEQUENCE)}: {cfg['name']}\")\n",
        "    print(f\"==============================\")\n",
        "\n",
        "    # build Task object (same style you already use)\n",
        "    task = Task(\n",
        "        cfg[\"name\"],\n",
        "        lambda env_id=cfg[\"env_id\"]: task_base(env_id, seed=0)\n",
        "    )\n",
        "\n",
        "    # load teacher\n",
        "    if method == \"D4_KL_LATENT\":\n",
        "        teacher_model, _ = load_sac_teacher(\n",
        "            task,\n",
        "            cfg[\"model_path\"],\n",
        "            cfg[\"vec_path\"],\n",
        "            seed=0\n",
        "        )\n",
        "            # ---- D4: KL + latent alignment ----\n",
        "        student, projector = train_distill_step_no_replay(\n",
        "            student=student,\n",
        "            projector=None,\n",
        "            method=\"D4_KL_LATENT\",\n",
        "            current_npz=cfg[\"npz_path\"],\n",
        "            teacher_sac_model=teacher_model,\n",
        "            epochs=50,\n",
        "            lambda_feat=0.2,\n",
        "            anchor_coeff=1e-6,\n",
        "        )\n",
        "    else:\n",
        "        student, _ = train_distill_step_no_replay(\n",
        "            student=student,\n",
        "            method=method,\n",
        "            current_npz=cfg[\"npz_path\"],\n",
        "            epochs=50,\n",
        "            anchor_coeff=1e-6,\n",
        "        )\n",
        "\n",
        "    # eval after each task\n",
        "    venv_eval = load_eval_env_with_vecnorm(cfg[\"env_id\"], cfg[\"vec_path\"], seed=0)\n",
        "    mean_ret, std_ret = eval_offline_student(student, venv_eval)\n",
        "    print(f\"--> Eval after task {i+1}: mean return = {mean_ret:.2f} +/- {std_ret:.2f}\")\n",
        "    venv_eval.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b13fae17",
      "metadata": {
        "id": "b13fae17"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "rl_rom",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}